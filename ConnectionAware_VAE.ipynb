{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN4Ik0UjFjMupXuRnXk9Q4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsaran-BioAI/AGILE/blob/main/ConnectionAware_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzjuzD8qCCm0",
        "outputId": "457757cf-8654-45ff-a05e-bfd8cf04985c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connecting the drive with Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W24TTrTZtvBl",
        "outputId": "63b92fe9-0024-4a78-9826-d39f9da70604"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%bash\n",
        "#MINICONDA_INSTALLER_SCRIPT=Miniconda3-latest-Linux-x86_64.sh\n",
        "#MINICONDA_PREFIX=/usr/local\n",
        "#wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "#chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "#./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "Y3CBY-5YP3KP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X8_QseIOVe8",
        "outputId": "0656493c-df14-488d-ef96-37277968f0ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANVtQ-SHOjlD",
        "outputId": "4fe9a102-137c-4c6f-d01e-aa1be9d6f8da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBNJUiG6w-rD",
        "outputId": "15d41d98-9d02-4dca-ab21-46f736a331dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install guacamol"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7alRIeqgOtzH",
        "outputId": "21e0df3a-a1c1-406e-e881-55e7c43a31b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: guacamol in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: joblib>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from guacamol) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.2 in /usr/local/lib/python3.10/dist-packages (from guacamol) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from guacamol) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from guacamol) (4.66.1)\n",
            "Requirement already satisfied: FCD>=1.1 in /usr/local/lib/python3.10/dist-packages (from guacamol) (1.2)\n",
            "Requirement already satisfied: rdkit-pypi>=2021.9.2.1 in /usr/local/lib/python3.10/dist-packages (from guacamol) (2022.9.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from FCD>=1.1->guacamol) (2.1.0+cu121)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from FCD>=1.1->guacamol) (2023.9.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi>=2021.9.2.1->guacamol) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->FCD>=1.1->guacamol) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->FCD>=1.1->guacamol) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->FCD>=1.1->guacamol) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjI7TwiOO3QD",
        "outputId": "198645c7-108e-44c5-81b0-dfef61027295"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ijtsjEd7gg",
        "outputId": "b4338635-9c17-4095-b686-a2ac106602f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging Operation Learning"
      ],
      "metadata": {
        "id": "L0eyGyhiZjOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI8NPUWKNEoW",
        "outputId": "215f3750-1928-4986-fcd4-746870ce70e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import networkx as nx\n",
        "from rdkit import Chem"
      ],
      "metadata": {
        "id": "-E-e2qS2yYfI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import arguments\n",
        "import model.mydataclass\n",
        "from arguments import parse_arguments\n",
        "from model.mydataclass import Paths"
      ],
      "metadata": {
        "id": "kMAgxnLJW40o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MolGraph:\n",
        "    idx: int\n",
        "    mol_graph: Chem.rdchem.Mol\n",
        "    merging_graph: nx.Graph\n",
        "\n",
        "    def __init__(self, smiles: str, idx: int=0) -> \"MolGraph\":\n",
        "        self.idx = idx\n",
        "        self.mol_graph = Chem.MolFromSmiles(smiles)\n",
        "        self.merging_graph = nx.Graph(Chem.rdmolops.GetAdjacencyMatrix(self.mol_graph))\n",
        "        for atom in self.mol_graph.GetAtoms():\n",
        "            self.merging_graph.nodes[atom.GetIdx()][\"atom_indices\"] = set([atom.GetIdx()])\n",
        "\n",
        "    def apply_merging_operation(self, motif: str, stats: Dict[str, int], indices: Dict[str, Dict[int, int]]) -> None:\n",
        "        if self.merging_graph.number_of_nodes() == 1:\n",
        "            return\n",
        "        new_graph = self.merging_graph.copy()\n",
        "        for (node1, node2) in self.merging_graph.edges:\n",
        "            if not new_graph.has_edge(node1, node2):\n",
        "                continue\n",
        "            atom_indices = new_graph.nodes[node1][\"atom_indices\"].union(new_graph.nodes[node2][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(self, atom_indices)\n",
        "            if motif_smiles == motif:\n",
        "                graph_before_merge = new_graph.copy()\n",
        "                merge_nodes(new_graph, node1, node2)\n",
        "                update_stats(self, graph_before_merge, new_graph, node1, node2, stats, indices, self.idx)\n",
        "        self.merging_graph = new_graph\n",
        "        indices[motif][self.idx] = 0\n",
        "\n",
        "    def apply_merging_operation_producer(self, motif: str, q: Queue) -> None:\n",
        "        if self.merging_graph.number_of_nodes() == 1:\n",
        "            return\n",
        "        new_graph = self.merging_graph.copy()\n",
        "        for (node1, node2) in self.merging_graph.edges:\n",
        "            if not new_graph.has_edge(node1, node2):\n",
        "                continue\n",
        "            atom_indices = new_graph.nodes[node1][\"atom_indices\"].union(new_graph.nodes[node2][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(self, atom_indices)\n",
        "            if motif_smiles == motif:\n",
        "                graph_before_merge = new_graph.copy()\n",
        "                merge_nodes(new_graph, node1, node2)\n",
        "                update_stats_producer(self, graph_before_merge, new_graph, node1, node2, q, self.idx)\n",
        "        q.put((motif, self.idx, new_graph))\n",
        "\n",
        "def load_batch_mols(batch: List[Tuple[int, str]]) -> List[MolGraph]:\n",
        "    return [MolGraph(smi, idx) for (idx, smi) in batch]\n",
        "\n",
        "def load_mols(train_path: str, num_workers: int) -> List[MolGraph]:\n",
        "    print(f\"[{datetime.now()}] Loading molecules...\")\n",
        "    smiles_list = [smi.strip(\"\\n\") for smi in open(train_path)]\n",
        "    smiles_list = [(i, smi) for (i, smi) in enumerate(smiles_list)]\n",
        "\n",
        "    batch_size = (len(smiles_list) - 1) // num_workers + 1\n",
        "    batches = [smiles_list[i : i + batch_size] for i in range(0, len(smiles_list), batch_size)]\n",
        "    mols: List[MolGraph]= []\n",
        "    with mp.Pool(num_workers) as pool:\n",
        "        for mols_batch in pool.imap(load_batch_mols, batches):\n",
        "            mols.extend(mols_batch)\n",
        "\n",
        "    print(f\"[{datetime.now()}] Loading molecules finished. Total: {len(mols)} molecules.\\n\")\n",
        "    return mols\n",
        "\n",
        "def fragment2smiles(mol: MolGraph, indices: List[int]) -> str:\n",
        "    smiles = Chem.MolFragmentToSmiles(mol.mol_graph, tuple(indices))\n",
        "    return Chem.MolToSmiles(Chem.MolFromSmiles(smiles, sanitize=False))\n",
        "\n",
        "def merge_nodes(graph: nx.Graph, node1: int, node2: int) -> None:\n",
        "    neighbors = [n for n in graph.neighbors(node2)]\n",
        "    atom_indices = graph.nodes[node1][\"atom_indices\"].union(graph.nodes[node2][\"atom_indices\"])\n",
        "    for n in neighbors:\n",
        "        if node1 != n and not graph.has_edge(node1, n):\n",
        "            graph.add_edge(node1, n)\n",
        "        graph.remove_edge(node2, n)\n",
        "    graph.remove_node(node2)\n",
        "    graph.nodes[node1][\"atom_indices\"] = atom_indices\n",
        "\n",
        "def get_stats_producer(batch: List[MolGraph], q: Queue):\n",
        "    for mol in batch:\n",
        "        for (node1, node2) in mol.merging_graph.edges:\n",
        "            atom_indices = mol.merging_graph.nodes[node1][\"atom_indices\"].union(mol.merging_graph.nodes[node2][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "            q.put((mol.idx, motif_smiles))\n",
        "    q.put(None)\n",
        "\n",
        "def get_stats_consumer(stats: Dict[str, int], indices: Dict[str, Dict[int, int]], q: Queue, num_workers: int):\n",
        "    num_tasks_done = 0\n",
        "    while True:\n",
        "        info = q.get()\n",
        "        if info == None:\n",
        "            num_tasks_done += 1\n",
        "            if num_tasks_done == num_workers:\n",
        "                break\n",
        "        else:\n",
        "            (idx, smi) = info\n",
        "            stats[smi] += 1\n",
        "            indices[smi][idx] += 1\n",
        "\n",
        "def get_stats(mols: List[MolGraph], num_workers: int) -> Tuple[Dict[str, int], Dict[int, int]]:\n",
        "    print(f\"[{datetime.now()}] Begin getting statistics.\")\n",
        "    stats = defaultdict(int)\n",
        "    indices = defaultdict(lambda: defaultdict(int))\n",
        "    if num_workers == 1:\n",
        "        for mol in mols:\n",
        "            for (node1, node2) in mol.merging_graph.edges:\n",
        "                atom_indices = mol.merging_graph.nodes[node1][\"atom_indices\"].union(mol.merging_graph.nodes[node2][\"atom_indices\"])\n",
        "                motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "                stats[motif_smiles] += 1\n",
        "                indices[motif_smiles][mol.idx] += 1\n",
        "    else:\n",
        "        batch_size = (len(mols) - 1) // num_workers + 1\n",
        "        batches = [mols[i : i + batch_size] for i in range(0, len(mols), batch_size)]\n",
        "        q = Queue()\n",
        "        producers = [Process(target=get_stats_producer, args=(batches[i], q)) for i in range(num_workers)]\n",
        "        [p.start() for p in producers]\n",
        "        get_stats_consumer(stats, indices, q, num_workers)\n",
        "        [p.join() for p in producers]\n",
        "    return stats, indices\n",
        "\n",
        "def update_stats(mol: MolGraph, graph: nx.Graph, new_graph: nx.Graph, node1: int, node2: int, stats: Dict[str, int], indices: Dict[str, Dict[int, int]], i: int):\n",
        "    neighbors1 = [n for n in graph.neighbors(node1)]\n",
        "    for n in neighbors1:\n",
        "        if n != node2:\n",
        "            atom_indices = graph.nodes[node1][\"atom_indices\"].union(graph.nodes[n][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "            stats[motif_smiles] -= 1\n",
        "            indices[motif_smiles][i] -= 1\n",
        "    neighbors2 = [n for n in graph.neighbors(node2)]\n",
        "    for n in neighbors2:\n",
        "        if n != node1:\n",
        "            atom_indices = graph.nodes[node2][\"atom_indices\"].union(graph.nodes[n][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "            stats[motif_smiles] -= 1\n",
        "            indices[motif_smiles][i] -= 1\n",
        "    neighbors = [n for n in new_graph.neighbors(node1)]\n",
        "    for n in neighbors:\n",
        "        atom_indices = new_graph.nodes[node1][\"atom_indices\"].union(new_graph.nodes[n][\"atom_indices\"])\n",
        "        motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "        stats[motif_smiles] += 1\n",
        "        indices[motif_smiles][i] += 1\n",
        "\n",
        "def update_stats_producer(mol: MolGraph, graph: nx.Graph, new_graph: nx.Graph, node1: int, node2: int, q: Queue, i: int):\n",
        "    neighbors1 = [n for n in graph.neighbors(node1)]\n",
        "    for n in neighbors1:\n",
        "        if n != node2:\n",
        "            atom_indices = graph.nodes[node1][\"atom_indices\"].union(graph.nodes[n][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "            q.put((motif_smiles, i, -1))\n",
        "    neighbors2 = [n for n in graph.neighbors(node2)]\n",
        "    for n in neighbors2:\n",
        "        if n != node1:\n",
        "            atom_indices = graph.nodes[node2][\"atom_indices\"].union(graph.nodes[n][\"atom_indices\"])\n",
        "            motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "            q.put((motif_smiles, i, -1))\n",
        "    neighbors = [n for n in new_graph.neighbors(node1)]\n",
        "    for n in neighbors:\n",
        "        atom_indices = new_graph.nodes[node1][\"atom_indices\"].union(new_graph.nodes[n][\"atom_indices\"])\n",
        "        motif_smiles = fragment2smiles(mol, atom_indices)\n",
        "        q.put((motif_smiles, i, 1))\n",
        "\n",
        "def apply_merging_operation_producer(motif: str, batch: List[MolGraph], q: Queue):\n",
        "    [mol.apply_merging_operation_producer(motif, q) for mol in batch]\n",
        "    q.put(None)\n",
        "\n",
        "def apply_merging_operation_consumer(mols: List[MolGraph], stats: Dict[str, int], indices: Dict[str, Dict[int, int]], q: Queue, num_workers: int):\n",
        "    num_tasks_done = 0\n",
        "    while True:\n",
        "        info = q.get()\n",
        "        if info == None:\n",
        "            num_tasks_done += 1\n",
        "            if num_tasks_done == num_workers:\n",
        "                break\n",
        "        else:\n",
        "            (motif, i, change) = info\n",
        "            if isinstance(change, int):\n",
        "                stats[motif] += change\n",
        "                indices[motif][i] += change\n",
        "            else:\n",
        "                assert isinstance(change, nx.Graph)\n",
        "                indices[motif][i] = 0\n",
        "                mols[i].merging_graph = change\n",
        "\n",
        "def apply_merging_operation(\n",
        "    motif: str,\n",
        "    mols: List[MolGraph],\n",
        "    stats: Dict[str, int],\n",
        "    indices: Dict[str, Dict[int, int]],\n",
        "    num_workers: int = 1,\n",
        "):\n",
        "    mols_to_process = [mols[i] for i, freq in indices[motif].items() if freq > 0]\n",
        "    if num_workers > 1:\n",
        "        batch_size = (len(mols_to_process) -1 ) // num_workers + 1\n",
        "        batches = [mols_to_process[i : i + batch_size] for i in range(0, len(mols_to_process), batch_size)]\n",
        "        q = Queue()\n",
        "        producers = [Process(target=apply_merging_operation_producer, args=(motif, batches[i], q)) for i in range(num_workers)]\n",
        "        [p.start() for p in producers]\n",
        "        apply_merging_operation_consumer(mols, stats, indices, q, num_workers)\n",
        "        [p.join() for p in producers]\n",
        "    else:\n",
        "        [mol.apply_merging_operation(motif, stats, indices) for mol in mols_to_process]\n",
        "    stats[motif] = 0\n",
        "\n",
        "def merging_operation_learning(\n",
        "    train_path: str,\n",
        "    operation_path: str,\n",
        "    num_iters: int,\n",
        "    min_frequency: int,\n",
        "    num_workers: int,\n",
        "    mp_threshold: int,\n",
        "):\n",
        "\n",
        "    print(f\"[{datetime.now()}] Learning merging operations from {train_path}.\")\n",
        "    print(f\"Number of workers: {num_workers}. Total number of CPUs: {mp.cpu_count()}.\\n\")\n",
        "\n",
        "    mols = load_mols(train_path, num_workers)\n",
        "    stats, indices = get_stats(mols, num_workers)\n",
        "\n",
        "    trace = []\n",
        "    dir = os.path.split(operation_path)[0]\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "    output = open(operation_path, \"w\")\n",
        "    for i in range(num_iters):\n",
        "        print(f\"[{datetime.now()}] Iteration {i}.\")\n",
        "        motif = max(stats, key=lambda x: (stats[x], x))\n",
        "        if stats[motif] < min_frequency:\n",
        "            print(f\"No motif has frequency >= {min_frequency}. Stopping.\\n\")\n",
        "            break\n",
        "        print(f\"[Iteration {i}] Most frequent motif: {motif}, frequency: {stats[motif]}.\\n\")\n",
        "        trace.append((motif, stats[motif]))\n",
        "\n",
        "        apply_merging_operation(\n",
        "            motif = motif,\n",
        "            mols = mols,\n",
        "            stats = stats,\n",
        "            indices = indices,\n",
        "            num_workers = num_workers if stats[motif] >= mp_threshold else 1,\n",
        "        )\n",
        "\n",
        "        output.write(f\"{motif}\\n\")\n",
        "\n",
        "    output.close()\n",
        "    print(f\"[{datetime.now()}] Merging operation learning finished.\")\n",
        "    print(f\"The merging operations are in {operation_path}.\\n\\n\")\n",
        "\n",
        "    return trace\n"
      ],
      "metadata": {
        "id": "KPnsIMXDYIFC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from arguments import parse_arguments"
      ],
      "metadata": {
        "id": "LUensBzIEMp5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.mydataclass import Paths"
      ],
      "metadata": {
        "id": "HEQdiSB4GCzW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse # Just checking of the arguments.py file is imported and working\n",
        "from arguments import parse_arguments\n",
        "args = parse_arguments()\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j50HFRIS9-DT",
        "outputId": "e77fe0e6-0967-42fc-e946-bce747bd6c80"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/data/', preprocess_dir='/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/preprocess/', output_dir='/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/output/', tensorboard_dir='/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/tensorboard/', dataset='QM9/', job_name='train_micam', model_dir=None, generate_path='samples', num_workers=60, cuda=0, seed=2, num_operations=1000, num_iters=3000, min_frequency=0, mp_thd=100000.0, hidden_size=256, atom_embed_size=[192, 16, 16, 16, 16], edge_embed_size=256, motif_embed_size=[256, 256], latent_size=64, depth=15, motif_depth=6, dropout=0.3, virtual=False, pooling='add', steps=300, batch_size=20, lr=0.005, lr_anneal_iter=5, lr_anneal_rate=0.99, grad_clip_norm=1.0, beta_warmup=30, beta_min=0.001, beta_max=0.3, beta_anneal_period=400, prop_weight=0.2, num_sample=100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hyperparameters were changed:\n",
        "\n",
        "parser.add_argument('--num_workers', type=int, default=60)  # Reduced number of workers\n",
        "\n",
        "parser.add_argument('--num_iters', type=int, default=1000)  # Fewer iterations (previously 3000)  \n",
        "\n",
        "parser.add_argument('--steps', type=int, default=10000)  # Fewer training steps (previously 50000)\n",
        "\n",
        "parser.add_argument('--batch_size', type=int, default=32)  # Smaller batch size (previously 128) - tried changing this but gave an error\n",
        "\n",
        "parser.add_argument('--dropout', type=float, default=0.2)  # Slightly lower dropout (previously 0.3)\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=1e-3)  # Lower learning rate (previously 1e5)"
      ],
      "metadata": {
        "id": "gdWMzUlHOL4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     args = parse_arguments()\n",
        "#     paths = Paths(args)\n",
        "\n",
        "#     learning_trace = merging_operation_learning(\n",
        "#         train_path = paths.train_path,\n",
        "#         operation_path = paths.operation_path,\n",
        "#         num_iters = args.num_iters,\n",
        "#         min_frequency = args.min_frequency,\n",
        "#         num_workers = args.num_workers,\n",
        "#         mp_threshold = args.mp_thd,\n",
        "#     )"
      ],
      "metadata": {
        "id": "Hn91ZrcoYL28"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motif Vocab Construction"
      ],
      "metadata": {
        "id": "srHAu1GuWFrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # just checking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q4Z4wjWS0iJ1",
        "outputId": "3b3c9c36-9ec6-4d1d-f23a-4dda9feac0de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/src'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Contrib\n",
        "from rdkit.Contrib import SA_Score\n",
        "from rdkit.Contrib.SA_Score import sascorer"
      ],
      "metadata": {
        "id": "0f0kWo3DWvXP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "import os\n",
        "import os.path as path\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from typing import List, Tuple\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from arguments import parse_arguments\n",
        "from model.mol_graph import MolGraph\n",
        "from model.mydataclass import Paths"
      ],
      "metadata": {
        "id": "642_FHD0WYKV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_operations(batch: List[Tuple[int, str]], mols_pkl_dir: str) -> Counter:\n",
        "    vocab = Counter()\n",
        "    pos = mp.current_process()._identity[0]\n",
        "    with tqdm(total = len(batch), desc=f\"Processing {pos}\", position=pos-1, ncols=80, leave=False) as pbar:\n",
        "        for idx, smi in batch:\n",
        "            mol = MolGraph(smi, tokenizer=\"motif\")\n",
        "            with open(path.join(mols_pkl_dir, f\"{idx}.pkl\"), \"wb\") as f:\n",
        "                pickle.dump(mol, f)\n",
        "            vocab = vocab + Counter(mol.motifs)\n",
        "            pbar.update()\n",
        "    return vocab\n",
        "\n",
        "def motif_vocab_construction(\n",
        "    train_path: str,\n",
        "    vocab_path: str,\n",
        "    operation_path: str,\n",
        "    num_operations: int,\n",
        "    num_workers: int,\n",
        "    mols_pkl_dir: str,\n",
        "):\n",
        "\n",
        "    print(f\"[{datetime.now()}] Construcing motif vocabulary from {train_path}.\")\n",
        "    print(f\"Number of workers: {num_workers}. Total number of CPUs: {mp.cpu_count()}.\")\n",
        "\n",
        "    data_set = [(idx, smi.strip(\"\\n\")) for idx, smi in enumerate(open(train_path))]\n",
        "    batch_size = (len(data_set) - 1) // num_workers + 1\n",
        "    batches = [data_set[i : i + batch_size] for i in range(0, len(data_set), batch_size)]\n",
        "    print(f\"Total: {len(data_set)} molecules.\\n\")\n",
        "\n",
        "    print(f\"Processing...\")\n",
        "    vocab = Counter()\n",
        "    os.makedirs(mols_pkl_dir, exist_ok=True)\n",
        "    MolGraph.load_operations(operation_path, num_operations)\n",
        "    func = partial(apply_operations, mols_pkl_dir=mols_pkl_dir)\n",
        "    with mp.Pool(num_workers, initializer=tqdm.set_lock, initargs=(mp.RLock(),)) as pool:\n",
        "        for batch_vocab in pool.imap(func, batches):\n",
        "            vocab = vocab + batch_vocab\n",
        "\n",
        "    atom_list = [x for (x, _) in vocab.keys() if x not in MolGraph.OPERATIONS]\n",
        "    atom_list.sort()\n",
        "    new_vocab = []\n",
        "    full_list = atom_list + MolGraph.OPERATIONS\n",
        "    for (x, y), value in vocab.items():\n",
        "        assert x in full_list\n",
        "        new_vocab.append((x, y, value))\n",
        "\n",
        "    index_dict = dict(zip(full_list, range(len(full_list))))\n",
        "    sorted_vocab = sorted(new_vocab, key=lambda x: index_dict[x[0]])\n",
        "    with open(vocab_path, \"w\") as f:\n",
        "        for (x, y, _) in sorted_vocab:\n",
        "            f.write(f\"{x} {y}\\n\")\n",
        "\n",
        "    print(f\"\\r[{datetime.now()}] Motif vocabulary construction finished.\")\n",
        "    print(f\"The motif vocabulary is in {vocab_path}.\\n\\n\")\n"
      ],
      "metadata": {
        "id": "sgE0HruOY_OC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     args = parse_arguments()\n",
        "#     paths = Paths(args)\n",
        "#     os.makedirs(paths.preprocess_dir, exist_ok=True)\n",
        "\n",
        "#     motif_vocab_construction(\n",
        "#         train_path = paths.train_path,\n",
        "#         vocab_path = paths.vocab_path,\n",
        "#         operation_path = paths.operation_path,\n",
        "#         num_operations = args.num_operations,\n",
        "#         mols_pkl_dir = paths.mols_pkl_dir,\n",
        "#         num_workers = args.num_workers,\n",
        "#     )"
      ],
      "metadata": {
        "id": "JC5ndmzsZBtz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Training Data"
      ],
      "metadata": {
        "id": "KR37I8Ybng9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "import os\n",
        "import os.path as path\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "from arguments import parse_arguments\n",
        "from model.mol_graph import MolGraph\n",
        "from model.mydataclass import Paths"
      ],
      "metadata": {
        "id": "9qufoKTrn5Ay"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S4155HjZkHob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_train_batch(batch: List[str], raw_dir: str, save_dir: str):\n",
        "    pos = mp.current_process()._identity[0]\n",
        "    with tqdm(total = len(batch), desc=f\"Processing {pos}\", position=pos-1, ncols=80, leave=False) as pbar:\n",
        "        for file in batch:\n",
        "            with open(path.join(raw_dir, file), \"rb\") as f:\n",
        "                mol: MolGraph = pickle.load(f)\n",
        "            data = mol.get_data()\n",
        "            torch.save(data, path.join(save_dir, file.split()[0]+\".pth\"))\n",
        "            pbar.update()\n",
        "\n",
        "def process_valid_batch(batch: List[Tuple[int, str]], save_dir: str):\n",
        "    pos = mp.current_process()._identity[0]\n",
        "    with tqdm(total = len(batch), desc=f\"Processing {pos}\", position=pos-1, ncols=80, leave=False) as pbar:\n",
        "        for idx, smi in batch:\n",
        "            mol = MolGraph(smi, tokenizer=\"motif\")\n",
        "            data = mol.get_data()\n",
        "            torch.save(data, path.join(save_dir, f\"{idx}.pth\"))\n",
        "            pbar.update()\n",
        "\n",
        "def make_trainig_data(\n",
        "    mols_pkl_dir: str,\n",
        "    valid_path: str,\n",
        "    vocab_path: str,\n",
        "    train_processed_dir: str,\n",
        "    valid_processed_dir: str,\n",
        "    vocab_processed_path: str,\n",
        "    num_workers: int,\n",
        "):\n",
        "\n",
        "    print(f\"[{datetime.now()}] Preprocessing traing data.\")\n",
        "    print(f\"Number of workers: {num_workers}. Total number of CPUs: {mp.cpu_count()}.\\n\")\n",
        "\n",
        "\n",
        "    print(f\"[{datetime.now()}] Loading training set from {mols_pkl_dir}.\\n\")\n",
        "    os.makedirs(train_processed_dir, exist_ok=True)\n",
        "    data_set = os.listdir(mols_pkl_dir)\n",
        "    batch_size = (len(data_set) - 1) // num_workers + 1\n",
        "    batches = [data_set[i : i + batch_size] for i in range(0, len(data_set), batch_size)]\n",
        "    func = partial(process_train_batch, raw_dir=mols_pkl_dir, save_dir=train_processed_dir)\n",
        "    with mp.Pool(num_workers, initializer=tqdm.set_lock, initargs=(mp.RLock(),)) as pool:\n",
        "        pool.map(func, batches)\n",
        "\n",
        "\n",
        "    print(f\"[{datetime.now()}] Preprocessing valid set from {valid_path}.\\n\")\n",
        "    os.makedirs(valid_processed_dir, exist_ok=True)\n",
        "    data_set = [(idx, smi.strip(\"\\n\")) for idx, smi in enumerate(open(valid_path))]\n",
        "    batch_size = (len(data_set) - 1) // num_workers + 1\n",
        "    batches = [data_set[i : i + batch_size] for i in range(0, len(data_set), batch_size)]\n",
        "    func = partial(process_valid_batch, save_dir=valid_processed_dir)\n",
        "    with mp.Pool(num_workers, initializer=tqdm.set_lock, initargs=(mp.RLock(),)) as pool:\n",
        "        pool.map(func, batches)\n",
        "\n",
        "    print(f\"[{datetime.now()}] Preprocessing motif vocabulary from {vocab_path}.\\n\")\n",
        "    vocab_data = MolGraph.preprocess_vocab()\n",
        "    with open(vocab_processed_path, \"wb\") as f:\n",
        "        torch.save(vocab_data, f)\n",
        "\n",
        "    print(f\"[{datetime.now()}] Preprocessing finished.\\n\\n\")"
      ],
      "metadata": {
        "id": "uaZCXi-Ho6va"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Contrib\n",
        "from rdkit.Contrib import SA_Score\n",
        "from rdkit.Contrib.SA_Score import sascorer"
      ],
      "metadata": {
        "id": "KY-qYX5xoVaH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     args = parse_arguments()\n",
        "#     paths  = Paths(args)\n",
        "\n",
        "#     MolGraph.load_operations(paths.operation_path, args.num_operations)\n",
        "#     MolGraph.load_vocab(paths.vocab_path)\n",
        "\n",
        "#     make_trainig_data(\n",
        "#         mols_pkl_dir = paths.mols_pkl_dir,\n",
        "#         valid_path = paths.valid_path,\n",
        "#         vocab_path = paths.vocab_path,\n",
        "#         train_processed_dir = paths.train_processed_dir,\n",
        "#         valid_processed_dir = paths.valid_processed_dir,\n",
        "#         vocab_processed_path = paths.vocab_processed_path,\n",
        "#         num_workers = args.num_workers,\n",
        "#     )\n"
      ],
      "metadata": {
        "id": "Ju82NxetkWK0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training MiCaM"
      ],
      "metadata": {
        "id": "OPrhFefsuw5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import os.path as path\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from arguments import parse_arguments\n",
        "from model.dataset import MolsDataset, batch_collate\n",
        "from model.MiCaM_VAE import MiCaM, VAE_Output\n",
        "from model.mol_graph import MolGraph\n",
        "from model.mydataclass import ModelParams, Paths, TrainingParams\n",
        "from model.scheduler import beta_annealing_schedule\n",
        "\n",
        "from model.vocab import MotifVocab, SubMotifVocab, Vocab"
      ],
      "metadata": {
        "id": "HhGPVev0u0Jg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args: argparse.Namespace):\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "    random.seed(args.seed)\n",
        "    paths = Paths(args)\n",
        "    tb = SummaryWriter(log_dir=paths.tensorboard_dir)\n",
        "\n",
        "    model_params = ModelParams(args)\n",
        "    training_params = TrainingParams(args)\n",
        "\n",
        "    MolGraph.load_operations(paths.operation_path)\n",
        "    MolGraph.load_vocab(paths.vocab_path)\n",
        "\n",
        "    os.makedirs(paths.output_dir)\n",
        "    log_file = path.join(paths.output_dir, \"train.log\")\n",
        "    print(f\"See {log_file} for log.\" )\n",
        "    logging.basicConfig(\n",
        "        filename = log_file,\n",
        "        filemode = \"w\",\n",
        "        format = \"[%(asctime)s]: %(message)s\",\n",
        "        level = logging.INFO\n",
        "    )\n",
        "\n",
        "    model = MiCaM(model_params)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=training_params.lr)\n",
        "\n",
        "    total_step, beta = 0, training_params.beta_min\n",
        "\n",
        "    logging.info(\"HyperParameters:\")\n",
        "    logging.info(model_params)\n",
        "    logging.info(training_params)\n",
        "\n",
        "    scheduler = lr_scheduler.ExponentialLR(optimizer, training_params.lr_anneal_rate)\n",
        "    beta_scheduler = beta_annealing_schedule(params=training_params, init_beta=beta, init_step=total_step)\n",
        "    train_dataset = MolsDataset(paths.train_processed_dir)\n",
        "\n",
        "    logging.info(f\"Begin training...\")\n",
        "    os.makedirs(paths.model_save_dir)\n",
        "    stop_train = False\n",
        "    i = 0\n",
        "    while True:\n",
        "        for input in DataLoader(dataset=train_dataset, batch_size=training_params.batch_size, shuffle=True, collate_fn=batch_collate):\n",
        "            print(i)\n",
        "\n",
        "            total_step += 1\n",
        "            model.zero_grad()\n",
        "\n",
        "            input = input\n",
        "            output: VAE_Output = model(input, beta=beta, prop_weight=training_params.prop_weight)\n",
        "\n",
        "            output.total_loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), training_params.grad_clip_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "            output.log_tb_results(total_step, tb, beta, scheduler.get_last_lr()[0])\n",
        "\n",
        "            if total_step % 50 == 0:\n",
        "                output.print_results(total_step, lr=scheduler.get_last_lr()[0], beta=beta)\n",
        "\n",
        "            if total_step % training_params.lr_anneal_iter == 0:\n",
        "                scheduler.step()\n",
        "\n",
        "            beta = beta_scheduler.step()\n",
        "\n",
        "            if total_step == training_params.steps:\n",
        "                stop_train = True\n",
        "                break\n",
        "\n",
        "        if stop_train: break\n",
        "\n",
        "    model.eval()\n",
        "    model.zero_grad()\n",
        "    #torch.cuda.empty_cache()\n",
        "    model_path = path.join(paths.model_save_dir,\"model.ckpt\")\n",
        "    motifs_embed_path = path.join(paths.model_save_dir,\"motifs_embed.ckpt\" )\n",
        "    with torch.no_grad():\n",
        "        ckpt = (model.state_dict(), optimizer.state_dict(), total_step, beta)\n",
        "        torch.save(ckpt, model_path)\n",
        "        model.save_motifs_embed(motifs_embed_path)\n",
        "    tb.close()"
      ],
      "metadata": {
        "id": "KWDFtbCUu4tY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    args = parse_arguments()\n",
        "    #torch.cuda.set_device(args.cuda)\n",
        "\n",
        "   train(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25AWioy5u-nx",
        "outputId": "ea8d0ed1-9688-4e0e-f4fc-f8b170cd783b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "See /content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/output/12-22/20:32:57-train_micam/train.log for log.\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "{3: {0: 0}, 4: {0: 1}, 5: {0: 2}, 6: {0: 3, 3: 4, 1: 5}, 8: {0: 6, 2: 7, 3: 8, 1: 9}, 9: {0: 10, 2: 11}, 10: {0: 12, 2: 13, 1: 14, 3: 15}, 11: {0: 16, 2: 17, 3: 18, 1: 19, 4: 20}, 12: {0: 21, 2: 22, 3: 23, 1: 24, 4: 25}, 13: {0: 26}, 143: {0: 27}, 272: {}, 18: {0: 28}, 19: {0: 29, 1: 30}, 21: {0: 31, 1: 32}, 22: {0: 33}, 24: {0: 34}, 27: {0: 35}, 29: {0: 36, 1: 37}, 33: {0: 38}, 165: {0: 39}, 38: {0: 40, 1: 41, 2: 42}, 39: {0: 43}, 42: {0: 44}, 43: {0: 45}, 47: {0: 46}, 49: {0: 47}, 52: {0: 48}, 54: {0: 49}, 60: {0: 50}, 61: {0: 51}, 63: {0: 52}, 64: {0: 53}, 66: {0: 54}, 68: {0: 55}, 69: {0: 56}, 209: {0: 57}, 87: {0: 58, 1: 59}, 88: {0: 60, 1: 61}, 96: {0: 62}, 100: {0: 63}, 102: {0: 64}, 114: {0: 65}, 120: {0: 66}, 124: {0: 67}}\n",
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-633a57f9f360>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#torch.cuda.set_device(args.cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-1e8cd8aaf85e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVAE_Output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprop_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/src/model/MiCaM_VAE.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, beta, prop_weight, dev)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mpred_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_props\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecoder_Output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         return VAE_Output(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/AGILE2/AI4Sci-MiCaM/src/model/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, input, dev)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mbatch_motif_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmotif_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmotifs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mbatch_motif_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_motif_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mmotif_node_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotif_graph_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmotif_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_motif_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Some PyTorch tensor like objects require a default value for `cuda`:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         return self.apply(lambda x: x.cuda(device, non_blocking=non_blocking),\n\u001b[0m\u001b[1;32m    312\u001b[0m                           *args)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    278\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    189\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Some PyTorch tensor like objects require a default value for `cuda`:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         return self.apply(lambda x: x.cuda(device, non_blocking=non_blocking),\n\u001b[0m\u001b[1;32m    312\u001b[0m                           *args)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    }
  ]
}